{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place du context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from findspark import init\n",
    "init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lit\n",
    "from pyspark.sql.types import LongType\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le contexte est récupéré si existant et dans l'autre cas il sera créé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = pyspark.SparkContext.getOrCreate() # ça marche pas pour moi avec sparkContext\n",
    "spark = SparkSession.builder.getOrCreate() # Du coup je fais une sparkSession (ça doit revenir presque au même je pense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"res\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.isfile(\"dac.tar.gz\"):\n",
    "    !wget https://s3-eu-west-1.amazonaws.com/kaggle-display-advertising-challenge-dataset/dac.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.isdir(data_dir):\n",
    "    makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier [`dac.tar.gz`](https://s3-eu-west-1.amazonaws.com/kaggle-display-advertising-challenge-dataset/dac.tar.gz) doit se situer dans le même répertoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.isfile(data_dir + \"/train.txt\") or not path.isfile(data_dir + \"/test.txt\"):\n",
    "    !tar -xvzf dac.tar.gz -C $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(data_dir + \"/train.txt\", header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45840617\n",
      "756554\n"
     ]
    }
   ],
   "source": [
    "print(df.count())\n",
    "print(df2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(_c0,StringType,true),StructField(_c1,StringType,true),StructField(_c2,StringType,true),StructField(_c3,StringType,true),StructField(_c4,StringType,true),StructField(_c5,StringType,true),StructField(_c6,StringType,true),StructField(_c7,StringType,true),StructField(_c8,StringType,true),StructField(_c9,StringType,true),StructField(_c10,StringType,true),StructField(_c11,StringType,true),StructField(_c12,StringType,true),StructField(_c13,StringType,true),StructField(_c14,StringType,true),StructField(_c15,StringType,true),StructField(_c16,StringType,true),StructField(_c17,StringType,true),StructField(_c18,StringType,true),StructField(_c19,StringType,true),StructField(_c20,StringType,true),StructField(_c21,StringType,true),StructField(_c22,StringType,true),StructField(_c23,StringType,true),StructField(_c24,StringType,true),StructField(_c25,StringType,true),StructField(_c26,StringType,true),StructField(_c27,StringType,true),StructField(_c28,StringType,true),StructField(_c29,StringType,true),StructField(_c30,StringType,true),StructField(_c31,StringType,true),StructField(_c32,StringType,true),StructField(_c33,StringType,true),StructField(_c34,StringType,true),StructField(_c35,StringType,true),StructField(_c36,StringType,true),StructField(_c37,StringType,true),StructField(_c38,StringType,true),StructField(_c39,StringType,true)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renommage des colonnes par : label, f1, f2, f3,..., f39 + Conversion des colonnes 0 à 13 inclu en float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(label=1.0, I1=0.0, I2=127.0, I3=1.0, I4=3.0, I5=1683.0, I6=19.0, I7=26.0, I8=17.0, I9=475.0, I10=0.0, I11=9.0, I12=0.0, I13=3.0, C1='05db9164', C2='8947f767', C3='11c9d79e', C4='52a787c8', C5='4cf72387', C6='fbad5c96', C7='18671b18', C8='0b153874', C9='a73ee510', C10='ceb10289', C11='77212bd7', C12='79507c6b', C13='7203f04e', C14='07d13a8f', C15='2c14c412', C16='49013ffe', C17='8efede7f', C18='bd17c3da', C19='f6a3e43b', C20='a458ea53', C21='35cd95c9', C22='ad3062eb', C23='c7dc6720', C24='3fdb382b', C25='010f6491', C26='49d68486')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mk_newNameCol():\n",
    "    res = ['label']\n",
    "    for i in range(1, 14):\n",
    "        res.append('I' + str(i))\n",
    "    for i in range(14, 14+27):\n",
    "        res.append('C' + str(i - 13))\n",
    "    return res\n",
    "\n",
    "new_name = mk_newNameCol()\n",
    "print(new_name)\n",
    "\n",
    "df3 = df2.select(*[col(c).alias(new_c) for c, new_c in zip(df2.columns, new_name)])\n",
    "df4 = df3.select(*(col(c).cast(\"float\") if i < 14 else col(c) for i, c in enumerate(df3.columns)))\n",
    "df4.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selectionner une partie des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir les feature C1 à C26 en `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.select(*(col(c) for c in df5.columns)) # copy\n",
    "fn_udf = udf(lambda x: int(\"0x\" + x, 16))\n",
    "for c in df6.columns[14:]:\n",
    "    df6 = df6.withColumn(c, fn_udf(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=1.0, I1=0.0, I2=127.0, I3=1.0, I4=3.0, I5=1683.0, I6=19.0, I7=26.0, I8=17.0, I9=475.0, I10=0.0, I11=9.0, I12=0.0, I13=3.0, C1='98275684', C2='2303194983', C3='298440606', C4='1386710984', C5='1291264903', C6='4222442646', C7='409410328', C8='185940084', C9='2805916944', C10='3467707017', C11='1998662615', C12='2035317867', C13='1912860750', C14='131152527', C15='739558418', C16='1224818686', C17='2399067775', C18='3172451290', C19='4137935931', C20='2757290579', C21='902665673', C22='2905629419', C23='3353110304', C24='1071331371', C25='17786001', C26='1238795398')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.schema\n",
    "df6.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.select(*(col(c) for c in df6.columns)) # copy\n",
    "for c in df7.columns[14:]:\n",
    "    df7 = df7.withColumn(c, df7[c].cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=1.0, I1=0.0, I2=127.0, I3=1.0, I4=3.0, I5=1683.0, I6=19.0, I7=26.0, I8=17.0, I9=475.0, I10=0.0, I11=9.0, I12=0.0, I13=3.0, C1=98275684, C2=2303194983, C3=298440606, C4=1386710984, C5=1291264903, C6=4222442646, C7=409410328, C8=185940084, C9=2805916944, C10=3467707017, C11=1998662615, C12=2035317867, C13=1912860750, C14=131152527, C15=739558418, C16=1224818686, C17=2399067775, C18=3172451290, C19=4137935931, C20=2757290579, C21=902665673, C22=2905629419, C23=3353110304, C24=1071331371, C25=17786001, C26=1238795398)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=df7.columns[1:],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = assembler.transform(df7).select(col(\"label\"), col(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(label,FloatType,true),StructField(features,VectorUDT,true)))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 54548421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.randomSplit([0.6, 0.4], seed)\n",
    "train = tmp[0]\n",
    "test = tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultilayerPerceptronClassifier(maxIter=10, layers=[39, 2], blockSize=128, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.5150086827090052\n"
     ]
    }
   ],
   "source": [
    "res = model.transform(test)\n",
    "pred_lbl = res.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(pred_lbl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrêt du context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
